{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S.Feature scaling. The StandardScaler is applied to standardize the features to have a mean=0 and variance=1. The scaler is fitted on the training set and then used to transform both the training and test sets. This is to prevent information leak from the test set into the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    \"people\": ['A', 'B', 'C'], \n",
    "    \"salary\": [70000,60000,52000], \n",
    "    \"age\": [45,44,40]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  people  salary  age\n",
      "0      A   70000   45\n",
      "1      B   60000   44\n",
      "2      C   52000   40\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  people    salary  age\n",
      "0      A  1.000000  1.0\n",
      "1      B  0.444444  0.8\n",
      "2      C  0.000000  0.0\n"
     ]
    }
   ],
   "source": [
    "c_1 = (data.iloc[:,1]-data.iloc[:,1].min())/(data.iloc[:,1].max()-data.iloc[:,1].min())\n",
    "c_2 = (data.iloc[:,2]-data.iloc[:,2].min())/(data.iloc[:,2].max()-data.iloc[:,2].min())\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    \"people\": ['A', 'B', 'C'], \n",
    "    \"salary\": c_1, \n",
    "    \"age\": c_2\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  people    salary  age\n",
      "0      A  1.000000  1.0\n",
      "1      B  0.444444  0.8\n",
      "2      C  0.000000  0.0\n"
     ]
    }
   ],
   "source": [
    "## Using function\n",
    "result=data\n",
    "def normalize_column(column):\n",
    "    min_val = column.min()\n",
    "    max_val = column.max()\n",
    "    normalized_column = (column - min_val) / (max_val - min_val)\n",
    "    return normalized_column\n",
    "\n",
    "result[\"salary\"] = normalize_column(data[\"salary\"])\n",
    "result[\"age\"] = normalize_column(data[\"age\"])\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  people    salary  age\n",
      "0      A  1.000000  1.0\n",
      "1      B  0.444444  0.8\n",
      "2      C  0.000000  0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize MinMaxScaler\n",
    "result=data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the \"Salary\" and \"Age\" columns\n",
    "result[[\"salary\", \"age\"]] = scaler.fit_transform(data[[\"salary\", \"age\"]])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0        1\n",
      "0  1.267500  0.92582\n",
      "1 -0.090536  0.46291\n",
      "2 -1.176965 -1.38873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result=data\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the DataFrame\n",
    "result = pd.DataFrame(scaler.fit_transform(data[['salary', 'age']]))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     salary       age\n",
      "0  1.034910  0.755929\n",
      "1 -0.073922  0.377964\n",
      "2 -0.960988 -1.133893\n"
     ]
    }
   ],
   "source": [
    "# OR\n",
    "\n",
    "result=data\n",
    "# Standardize the DataFrame using pandas\n",
    "result = (result[['salary', 'age']] - result[['salary', 'age']].mean()) / result[['salary', 'age']].std()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guidelines:\n",
    "\n",
    "For algorithms that rely on distance calculations or gradient descent, normalization is often preferred because it scales the features to a specific range, preventing one feature from dominating others.\n",
    "\n",
    "For algorithms that assume a standard normal distribution of the input data or those that rely on the mean and variance of the features (e.g., linear regression, logistic regression), standardization is usually more appropriate.\n",
    "\n",
    "In many cases, trying both standardization and normalization and comparing the performance of your model can help determine which preprocessing technique works better for your specific problem.\n",
    "\n",
    "Remember that the choice between standardization and normalization is not strictly black and white, and the optimal choice may depend on the characteristics of your data and the requirements of your chosen machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Normalization                    | Standardization                                   |\n",
    "|:-----------------------------------:|:---------------------------------------------------:|\n",
    "| This method scales the model using minimum and maximum values. | This method scales the model using the mean and standard deviation. |\n",
    "| When features are on various scales, it is functional. | When a variable's mean and standard deviation are both set to 0, it is beneficial. |\n",
    "| Values on the scale fall between [0, 1] and [-1, 1]. | Values on a scale are not constrained to a particular range. |\n",
    "| Additionally known as scaling normalization. | This process is called Z-score normalization. |\n",
    "| When the feature distribution is unclear, it is helpful. | When the feature distribution is consistent, it is helpful. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legendary-ml-vETwCYDa-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
